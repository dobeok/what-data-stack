created_utc,author,score,ETL,Data Warehouse,Data Transformation,BI,Exploratory Data Analysis,Company Size,Company Industry,Company HQ,ETL_clean,ETL_weight,Data Warehouse_clean,Data Warehouse_weight,Data Transformation_clean,Data Transformation_weight,BI_clean,BI_weight,Exploratory Data Analysis_clean,Exploratory Data Analysis_weight
1659294345.0,AutoModerator,1,,,,,,,,,[''],[{'': 1}],[''],[{'': 1}],[''],[{'': 1}],[''],[{'': 1}],[''],[{'': 1}]
1659306558.0,syphilicious,33,SSIS & BIML,SQL server on prem,SQL stored procedures,Power BI,Excel,150+,Energy/ natural resources,"Texas, USA","['Biml', 'Ssis']","[{'Biml': 33}, {'Ssis': 33}]",['Sql server prem'],[{'Sql server prem': 33}],['Sql stored procedures'],[{'Sql stored procedures': 33}],['Power bi'],[{'Power bi': 33}],['Excel'],[{'Excel': 33}]
1659299153.0,rudboi12,37,Azure Data factory,Azure data lake gen 2,Spark with Databricks (pyspark),PowerBI,Databricks notebooks,Donâ€™t know probably at 100k+,Consumer Goods,HQ in US but  working for UK region only.,['Azure data factory'],[{'Azure data factory': 37}],['Azure data gen 2'],[{'Azure data gen 2': 37}],[],[],['Powerbi'],[{'Powerbi': 37}],['Databricks notebooks'],[{'Databricks notebooks': 37}]
1659300309.0,hesperoyucca,11,,,,,,,,,[''],[{'': 11}],[''],[{'': 11}],[''],[{'': 11}],[''],[{'': 11}],[''],[{'': 11}]
1659293878.0,Pleasant_Type_4547,27,"Fivetran, Stitch",Snowflake,dbt,"Looker, Metabase",Google Colab,50,E-commerce,"London, UK","['Fivetran', 'Stitch']","[{'Fivetran': 27}, {'Stitch': 27}]",['Snowflake'],[{'Snowflake': 27}],['Dbt'],[{'Dbt': 27}],"['Looker', 'Metabase']","[{'Looker': 27}, {'Metabase': 27}]",['Google colab'],[{'Google colab': 27}]
1659307709.0,reborndu,9,"Azure Data Factory (Dynamic pipelines,so I just really run parametrized executions)",Azure Data Lake/Snowflake,"Databricks ((Mostly SQL & Scala, few Pyspark)",PowerBI,Databricks/Snowflake,~50k,Paints & chemicals,"HQ in the US but working from Mexico (So pay is 10 times less than a similar job from the US, so...)",[],[],['Snowflake'],[{'Snowflake': 9}],[],[],['Powerbi'],[{'Powerbi': 9}],"['Databricks', 'Snowflake']","[{'Databricks': 9}, {'Snowflake': 9}]"
1659306773.0,booyahtech,7,Azure Data Factory,Azure Synapse Dedicated SQL Pool / Snowflake,Databricks (Python / Spark if bigger datasets),Power BI,Databricks,200K +,FMCG,,['Azure data factory'],[{'Azure data factory': 7}],['Snowflake'],[{'Snowflake': 7}],[],[],['Power bi'],[{'Power bi': 7}],['Databricks'],[{'Databricks': 7}]
1659314548.0,lljdu77_-bvd,7,Python and Cron,Postgres AWS RDS,Python and SQL,Dashboards written in Python,SQL and Python,,Data,Brazil,"['Python', 'Cron']","[{'Python': 7}, {'Cron': 7}]",['Postgres aws rds'],[{'Postgres aws rds': 7}],"['Python', 'Sql']","[{'Python': 7}, {'Sql': 7}]",['Dashboards python'],[{'Dashboards python': 7}],"['Python', 'Sql']","[{'Python': 7}, {'Sql': 7}]"
1659329149.0,mhoss2008,7,,,/Snowflake,,,,,,[''],[{'': 7}],[''],[{'': 7}],"['', 'Snowflake']","[{'': 7}, {'Snowflake': 7}]",[''],[{'': 7}],[''],[{'': 7}]
1659303104.0,lahma_mama,5,Stitch/Meltano,Big Query,dbt or big query,Tableau,Tableau,30-50 (start-up),E-commerce,USA,"['Stitch', 'Meltano']","[{'Stitch': 5}, {'Meltano': 5}]",['Big query'],[{'Big query': 5}],['Dbt'],[{'Dbt': 5}],['Tableau'],[{'Tableau': 5}],['Tableau'],[{'Tableau': 5}]
1659334412.0,askvinni,5,Dagster,Snowflake,dbt,"Metabase (not in place, no BI yet)",Colab/Notebooks,~50,BioTech,,['Dagster'],[{'Dagster': 5}],['Snowflake'],[{'Snowflake': 5}],['Dbt'],[{'Dbt': 5}],[],[],['Colab'],[{'Colab': 5}]
1659298286.0,Spartyon,13,airflow,bigquery,python/airflow,jupyter,metabase,8,analytics consulting,"detroit, mi USA",['Airflow'],[{'Airflow': 13}],[],[],"['Python', 'Airflow']","[{'Python': 13}, {'Airflow': 13}]",['Jupyter'],[{'Jupyter': 13}],['Metabase'],[{'Metabase': 13}]
1659302199.0,fruity231,5,,,,,0,,,,[''],[{'': 5}],[''],[{'': 5}],[''],[{'': 5}],[''],[{'': 5}],['0'],[{'0': 5}]
1659548051.0,Firefox1950,4,Azure Data Factory,Azure Data Lake,Databricks (pyspark),Power BI,Databricks,3000,Public Sector,"Ontario, Canada",['Azure data factory'],[{'Azure data factory': 4}],[],[],[],[],['Power bi'],[{'Power bi': 4}],['Databricks'],[{'Databricks': 4}]
1659298982.0,CingKan,7,Airbyte,Snowflake,Dbt,looker,Looker/ python,13,Insurance,"Reading , UK",['Airbyte'],[{'Airbyte': 7}],['Snowflake'],[{'Snowflake': 7}],['Dbt'],[{'Dbt': 7}],['Looker'],[{'Looker': 7}],"['Python', 'Looker']","[{'Python': 7}, {'Looker': 7}]"
1659311492.0,jmhcodes,3,Airflow,Redshift + HDFS,Spark + Kafka/Flink + Segment (phasing out),Looker (not a big fan),"Personally Jupiter, company wide excel + looker + whatever they choose",~140,Food eCommerce,US,['Airflow'],[{'Airflow': 3}],"['Hdfs', 'Redshift']","[{'Hdfs': 3}, {'Redshift': 3}]","['', 'Spark']","[{'': 3}, {'Spark': 3}]",[],[],"['Looker', 'Excel']","[{'Looker': 3}, {'Excel': 3}]"
1659339155.0,Laxuz,3,"Spark, Sqoop, Airflow",Snowflake,DBT,"Qlik, Looker, Tableau","Dataiku, Databricks",5.000,Media and entertainment,"Brussels, Belgium","['Spark', 'Sqoop', 'Airflow']","[{'Spark': 3}, {'Sqoop': 3}, {'Airflow': 3}]",['Snowflake'],[{'Snowflake': 3}],['Dbt'],[{'Dbt': 3}],"['Qlik', 'Looker', 'Tableau']","[{'Qlik': 3}, {'Looker': 3}, {'Tableau': 3}]",['Databricks'],[{'Databricks': 3}]
1659342394.0,code_pusher,3,"DBT, Spark(Databricks)","Snowflake, SSIS","DBT scripts, Spark Jobs, Stored procs",Tableau,"Databricks Notebooks, Snowflake AdHoc Queries",3000,"Media, Advertising",London,"['Dbt', 'Spark']","[{'Dbt': 3}, {'Spark': 3}]",['Snowflake'],[{'Snowflake': 3}],['Dbt scripts'],[{'Dbt scripts': 3}],['Tableau'],[{'Tableau': 3}],"['Databricks notebooks', 'Snowflake adhoc queries']","[{'Databricks notebooks': 3}, {'Snowflake adhoc queries': 3}]"
1659384961.0,aayushdotjain,3,,,,,,,,,[''],[{'': 3}],[''],[{'': 3}],[''],[{'': 3}],[''],[{'': 3}],[''],[{'': 3}]
1659313330.0,86BillionFireflies,8,0 people in research group,Data Warehouse,Data Transformation,BI,EDA,Company Size,Company Industry [optional],HQ,['0 research group'],[{'0 research group': 8}],['Data warehouse'],[{'Data warehouse': 8}],['Data transformation'],[{'Data transformation': 8}],['Bi'],[{'Bi': 8}],['Eda'],[{'Eda': 8}]
1659300884.0,LewWariat,5,Airflow,BigQuery,We transform it in BigQuery 95% of the time (only some basics like schema testing in Airflow) - ELT approach,"Data Studio (I strongly dislike it btw, I don't know why folks don't want to use Looker)","00 company (I work at consulting), I shouldn't say more.",,,,['Airflow'],[{'Airflow': 5}],[],[],['We transform bigquery 95   elt approach'],[{'We transform bigquery 95   elt approach': 5}],[],[],['I shouldnt more'],[{'I shouldnt more': 5}]
1659304115.0,heyitscactusjack,6,Dagster and SSIS (separately),SQL Server on prem,Dagster and SSIS,Excel with mdx cubes and also microstrategy but moving on to PowerBI,"Excel, PowerBI or Jupyter notebook","80-150k people globally, but probably 3000 locally",Insurance,Munich,['Dagster'],[{'Dagster': 6}],['Sql server prem'],[{'Sql server prem': 6}],"['Ssis', 'Dagster']","[{'Ssis': 6}, {'Dagster': 6}]","['Excel mdx cubes', 'Also microstrategy moving powerbi']","[{'Excel mdx cubes': 6}, {'Also microstrategy moving powerbi': 6}]",['Excel'],[{'Excel': 6}]
1659297126.0,Culpgrant21,4,Matillion ETL,Snowflake,Matillion ETL,Qliksense,Up to the analyst but probably just Snowflake Snowsight (wish more people used r or python). A lot of older people at my company use Access (it is a nightmare).,"5,000",Software,United States,['Matillion etl'],[{'Matillion etl': 4}],['Snowflake'],[{'Snowflake': 4}],['Matillion etl'],[{'Matillion etl': 4}],['Qliksense'],[{'Qliksense': 4}],[],[]
1659301534.0,cshoneybadger,4,,,,000,,,,,[''],[{'': 4}],[''],[{'': 4}],[''],[{'': 4}],['000'],[{'000': 4}],[''],[{'': 4}]
1659310107.0,bsbpe,2,4hours,,,,,,,,['4hours'],[{'4hours': 2}],[''],[{'': 2}],[''],[{'': 2}],[''],[{'': 2}],[''],[{'': 2}]
1659313797.0,Tetkobear,2,Azure Data Factory,Snowflake,SQL stored procs in Snowflake,Tableau and Power BI,"Databricks, Alteryx",5000+,,US,['Azure data factory'],[{'Azure data factory': 2}],['Snowflake'],[{'Snowflake': 2}],[],[],"['Tableau', 'Power bi']","[{'Tableau': 2}, {'Power bi': 2}]",['Databricks'],[{'Databricks': 2}]
1659317418.0,rwby00,2,AWS Glue / Airflow,Redshift,dbt,Power Bi / Metabase,Jupyter (deepnote) / Google Sheets,128,HR Saas,"Tokyo, Japan","['Airflow', 'Aws glue']","[{'Airflow': 2}, {'Aws glue': 2}]",['Redshift'],[{'Redshift': 2}],['Dbt'],[{'Dbt': 2}],"['Metabase', 'Power bi']","[{'Metabase': 2}, {'Power bi': 2}]",['Google sheets'],[{'Google sheets': 2}]
1659318058.0,sl00k,2,) Fivetran / Reverse ETL - Census,) Redshift thinking of transitioning to Snowflake (any info on if this is worth?),) dbt,) Mode,) Mode / Jupyter,) 120,) Tech Series A,,['Reverse etl  census'],[{'Reverse etl  census': 2}],[],[],[],[],[],[],['Jupyter'],[{'Jupyter': 2}]
1659327748.0,fuchibolguy,2,Python,Snowflake,Dataiku (wtf?),power bi,power bi,,,,['Python'],[{'Python': 2}],['Snowflake'],[{'Snowflake': 2}],[],[],['Power bi'],[{'Power bi': 2}],['Power bi'],[{'Power bi': 2}]
1659331207.0,anurag_bhoga,2,"ADF, Databricks( Delta Lake)",Snowflake,Databricks,"QlikSense, Power BI","Internal systems , later with airport conveyor belts",**Company Size** (approx # employees) 100k,"**Company Industry**  Manufacturing, Airports",,['Databricks'],[{'Databricks': 2}],['Snowflake'],[{'Snowflake': 2}],['Databricks'],[{'Databricks': 2}],"['Bi', 'Qliksense']","[{'Bi': 2}, {'Qliksense': 2}]","['Later airport conveyor belts', 'Internal systems']","[{'Later airport conveyor belts': 2}, {'Internal systems': 2}]"
1659333186.0,gordonnewland,2,"Airflow, Fivetran",Snowflake,DBT,Qlik,"R, Qlik",500+,Tech,,"['Fivetran', 'Airflow']","[{'Fivetran': 2}, {'Airflow': 2}]",['Snowflake'],[{'Snowflake': 2}],['Dbt'],[{'Dbt': 2}],['Qlik'],[{'Qlik': 2}],"['Qlik', 'R']","[{'Qlik': 2}, {'R': 2}]"
1659341698.0,badge,2,"Airflow (lots of custom industry stuff), Stitch (Saleforce, 3rd party db), Hevo (Stripe)",Snowflake,dbt,"Hex (replaced Mode, because we use it for (5) and Hex is more powerful)",Hex,15,Energy,Toronto/Remote,[],[],['Snowflake'],[{'Snowflake': 2}],['Dbt'],[{'Dbt': 2}],[],[],['Hex'],[{'Hex': 2}]
1659356908.0,Carsina,2,500,,,,,,,,['500'],[{'500': 2}],[''],[{'': 2}],[''],[{'': 2}],[''],[{'': 2}],[''],[{'': 2}]
1659380520.0,biellls,2,Typhoon Orchestrator + AWS Lambda,Postgres or DuckDB,Power BI,,,,,,"['Aws lambda', 'Typhoon orchestrator']","[{'Aws lambda': 2}, {'Typhoon orchestrator': 2}]",['Duckdb'],[{'Duckdb': 2}],['Power bi'],[{'Power bi': 2}],[''],[{'': 2}],[''],[{'': 2}]
1659383871.0,Competitive-Emu-3916,2,Keboola,Snowflake,Keboola Transformations,Looker,Python notebooks,100,Tech,Prague,['Keboola'],[{'Keboola': 2}],['Snowflake'],[{'Snowflake': 2}],[],[],['Looker'],[{'Looker': 2}],[],[]
1659442448.0,j__neo,2,"AWS DMS or AWS Kinesis for first-party data, Fivetran for third-party data",Snowflake,dbt,Mode or Looker,Mode and Jupyter Notebooks,"3000+ employees. 100+ data professionals (i.e. data analysts, data engineers, analytics engineers).",Software and Media,,"['Fivetran thirdparty data', 'Aws kinesis firstparty data', 'Aws dms']","[{'Fivetran thirdparty data': 2}, {'Aws kinesis firstparty data': 2}, {'Aws dms': 2}]",['Snowflake'],[{'Snowflake': 2}],['Dbt'],[{'Dbt': 2}],"['Looker', 'Mode']","[{'Looker': 2}, {'Mode': 2}]",['Mode'],[{'Mode': 2}]
1659305372.0,Simonaque,6,Fivetran/ some (very little) Airbyte,Snowflake,dbt,Looker,"Not Sure, probably Jupyter",900+,MedTech,"Ottawa, Canada",['Fivetran'],[{'Fivetran': 6}],['Snowflake'],[{'Snowflake': 6}],['Dbt'],[{'Dbt': 6}],['Looker'],[{'Looker': 6}],['Not sure'],[{'Not sure': 6}]
1659305932.0,Affectionate_Answer9,2,Airflow,"Lakehouse architecture, data is primarily stored in s3 using parquet/hudi storage formats but we also have a few other data stores depending on the use case (snowflake, clickhouse and postgres)",Spark and Presto deployed on AWS EMR,Looker,Shared jupyter notebooks which can connect to our datalake/dwh and looker,about 500,tech,bay area,['Airflow'],[{'Airflow': 2}],"['Data primarily stored s3 using parquet', 'Lakehouse architecture']","[{'Data primarily stored s3 using parquet': 2}, {'Lakehouse architecture': 2}]",['Spark'],[{'Spark': 2}],['Looker'],[{'Looker': 2}],['Looker'],[{'Looker': 2}]
1659315633.0,notazoroastrian,2,Spark (Databricks),Delta Lake/Hive (Databricks),Spark/Pandas (Databricks),Looker,IPynb (Databricks),"200 employees in USA, 5 person data analytics team",,,[],[],['Delta lake'],[{'Delta lake': 2}],['Spark'],[{'Spark': 2}],['Looker'],[{'Looker': 2}],[],[]
1659325164.0,tortuga_jester,2,Fivetran,Snowflake,DBT,Tableau,Mode,400,SaaS / RestaurantTech,,['Fivetran'],[{'Fivetran': 2}],['Snowflake'],[{'Snowflake': 2}],['Dbt'],[{'Dbt': 2}],['Tableau'],[{'Tableau': 2}],['Mode'],[{'Mode': 2}]
1659302411.0,ZoomCallOfCthulhu,2,Python/SQL,"Postgres, considering moving to Snowflake since our DWH is approaching a terabyte","Python/SQL, looking into DBT",Qlik Sense,-,1000,healthcare,Netherlands,"['Python', 'Sql']","[{'Python': 2}, {'Sql': 2}]",['Considering moving snowflake dwh approaching terabyte'],[{'Considering moving snowflake dwh approaching terabyte': 2}],"['Python', 'Sql']","[{'Python': 2}, {'Sql': 2}]",[],[],[''],[{'': 2}]
1659319535.0,Geraldks,1,Airflow,"Snowflake, Redshift (about to sunset)","Dbt, Python/ Spark","Periscope, Metabase (mainly for monitoring)",Jupyter,~1000 globally,Fintech,NY & KL,['Airflow'],[{'Airflow': 1}],['Snowflake'],[{'Snowflake': 1}],"['Python', 'Dbt', 'Spark']","[{'Python': 1}, {'Dbt': 1}, {'Spark': 1}]",['Periscope'],[{'Periscope': 1}],['Jupyter'],[{'Jupyter': 1}]
1659327529.0,twadftw10,1,Airflow and Cdc with Debezium/kafka,Snowflake,Python/sql,Sisense,Jupyter Notebooks,700,IT/Security,"Denver, US",['Airflow'],[{'Airflow': 1}],['Snowflake'],[{'Snowflake': 1}],"['Python', 'Sql']","[{'Python': 1}, {'Sql': 1}]",['Sisense'],[{'Sisense': 1}],[],[]
1659298794.0,Doyale_royale,1,Talend / Qlik cdc,Oracle,Talend,Micro strategy,,6000,,,"['Talend', 'Qlik cdc']","[{'Talend': 1}, {'Qlik cdc': 1}]",['Oracle'],[{'Oracle': 1}],['Talend'],[{'Talend': 1}],['Micro strategy'],[{'Micro strategy': 1}],[''],[{'': 1}]
1659310338.0,mictom9,1,Python,Postgres,dbt,Power BI,Databricks if my local cluster is too slow,500,Gaming,,['Python'],[{'Python': 1}],[],[],['Dbt'],[{'Dbt': 1}],['Power bi'],[{'Power bi': 1}],[],[]
1659317851.0,toadkiller,1,"Fivetran in, Hightouch out, in house packages for a few integrations, all orchestrated with airflow",BigQuery,dbt,Looker,Looker,<100,Fintech,,"['Orchestrated airflow', 'Hightouch out', 'Packages integrations']","[{'Orchestrated airflow': 1}, {'Hightouch out': 1}, {'Packages integrations': 1}]",[],[],['Dbt'],[{'Dbt': 1}],['Looker'],[{'Looker': 1}],['Looker'],[{'Looker': 1}]
1659322270.0,master_sq,1,Airflow,Data VaultðŸ˜‚ ( Data Warehouse <> Database),SQL,Tableau,"Tableau, SQL, Python",1000,Fintech,Global,['Airflow'],[{'Airflow': 1}],[],[],['Sql'],[{'Sql': 1}],['Tableau'],[{'Tableau': 1}],"['Python', 'Tableau', 'Sql']","[{'Python': 1}, {'Tableau': 1}, {'Sql': 1}]"
1659323592.0,justwantanaccount,1,", 2, and 3.","8K+ employee healthcare distribution company, headquartered in the US",,"/5 we recently started Tableau a few years ago, but they were using WebFocus before then. Most people use NQuire, which is a way to query the TIBCO tables through a GUI and download into Excel. My team is steeped deeply into Access, yuck.",,,,,"['', '2', '3']","[{'': 1}, {'2': 1}, {'3': 1}]","['Headquartered us', '8k', 'Employee healthcare distribution company']","[{'Headquartered us': 1}, {'8k': 1}, {'Employee healthcare distribution company': 1}]",[''],[{'': 1}],"['', 'Using webfocus nquire', 'Query tibco tables gui', '5 recently started tableau years ago', 'Yuck', 'Download into excel steeped deeply into access']","[{'': 1}, {'Using webfocus nquire': 1}, {'Query tibco tables gui': 1}, {'5 recently started tableau years ago': 1}, {'Yuck': 1}, {'Download into excel steeped deeply into access': 1}]",[''],[{'': 1}]
1659323877.0,saiyan6174,1,AWS Glue,AWS RedShift,Glue Spark + RedShift SQL,PowerBI,Notebooks + SQL,50+,Consulting firm,"client in Canada, company in India",['Aws glue'],[{'Aws glue': 1}],[],[],"['Redshift sql', 'Glue spark']","[{'Redshift sql': 1}, {'Glue spark': 1}]",['Powerbi'],[{'Powerbi': 1}],['Sql'],[{'Sql': 1}]
1659323941.0,Balance-Time,1,,,,,,,,,[''],[{'': 1}],[''],[{'': 1}],[''],[{'': 1}],[''],[{'': 1}],[''],[{'': 1}]
1659330980.0,jiejenn,1,Apache Airflow,BigQuery/SQL Server,dbt/Python (pandas),Python/Power BI,Python/SQL/Excel,,,,[],[],[],[],['Dbt'],[{'Dbt': 1}],"['Python', 'Power bi']","[{'Python': 1}, {'Power bi': 1}]","['Python', 'Excel', 'Sql']","[{'Python': 1}, {'Excel': 1}, {'Sql': 1}]"
1659333704.0,throw_mob,1,"Good at start , but as main T is SQL, it makes Matillion kinda obsolete. Custom Python program to fetch data from sources to object storage is quite easy to make and control",Snowflake,"i could consider using dbt, but SQL code in git and versioned schemas work nice",Little bit of disapointed on it. Not as easy and cost effective as it was sold. You need to be aake when crating models for normal users,plain old SQL,50,Fintech,,"['Makes matillion kinda obsolete custom python program fetch data sources storage easy make', 'Control', 'Good', 'T sql']","[{'Makes matillion kinda obsolete custom python program fetch data sources storage easy make': 1}, {'Control': 1}, {'Good': 1}, {'T sql': 1}]",['Snowflake'],[{'Snowflake': 1}],"['Sql code git', 'I using dbt', 'Versioned schemas nice']","[{'Sql code git': 1}, {'I using dbt': 1}, {'Versioned schemas nice': 1}]","['Little disapointed easy', 'Cost effective sold aake crating models normal users']","[{'Little disapointed easy': 1}, {'Cost effective sold aake crating models normal users': 1}]",['Plain sql'],[{'Plain sql': 1}]
1659337818.0,dataengg_geek,1,Hevo/Airbyte/Fivetran 2. Snowflake/Google BigQuery/Redshift  4. Power BI/Metabase 5. Excel 6.100+ 7. USA,,,,,,,,"['Airbyte', 'Google bigquery']","[{'Airbyte': 1}, {'Google bigquery': 1}]",[''],[{'': 1}],[''],[{'': 1}],[''],[{'': 1}],[''],[{'': 1}]
1659338080.0,burpeesnrun,1,SSIS,SQL Server on prem,Stored procedures,"Sisense, but migrating to Tableau soon.",Excel,500+,Insurance,,['Ssis'],[{'Ssis': 1}],['Sql server prem'],[{'Sql server prem': 1}],[],[],['Sisense'],[{'Sisense': 1}],['Excel'],[{'Excel': 1}]
1659342252.0,lurkerbelow,1,"SAP Data Services, Apache Airflow",MSSQL on prem,"SAP Data Services, Apache Airflow","SAP Business Objects, PBI, in house developed chart service","Anything really, form Excel to Notebooks to PBI",4000+,Tertiary education,,['Sap data services'],[{'Sap data services': 1}],[],[],['Apache airflow'],[{'Apache airflow': 1}],"['Developed service', 'Sap business objects']","[{'Developed service': 1}, {'Sap business objects': 1}]","['Anything really', 'Excel notebooks pbi']","[{'Anything really': 1}, {'Excel notebooks pbi': 1}]"
1659348818.0,olvsegun,1,Airflow/Python,BigQuery,SQL/Beam (Dataflow) / Pyspark,Tableau/ Data Studio,BQ / Python,about 2K I think,Adtech,The US but a global company. I work in the EU region,"['Python', 'Airflow']","[{'Python': 1}, {'Airflow': 1}]",[],[],"['Pyspark', 'Sql']","[{'Pyspark': 1}, {'Sql': 1}]","['Tableau', 'Data studio']","[{'Tableau': 1}, {'Data studio': 1}]",['Python'],[{'Python': 1}]
1659349684.0,OnlyMeandMyThoughts,1,ETL - Dataddo,Data Warehouse - Google BQ,Data Transformation - dbt,BI - Tableau,Exploratory Data Analysis - Tableau,Company Size - around 200,E-commerce,,['Etl  dataddo'],[{'Etl  dataddo': 1}],[],[],[],[],['Bi  tableau'],[{'Bi  tableau': 1}],['Exploratory data analysis  tableau'],[{'Exploratory data analysis  tableau': 1}]
1659356968.0,Anxious_Reporter,1,ETL: Airflow + Sqoop + pysftp,Data Warehouse: HDFS --> SQL Server,Data Transformation: python + pyspark,BI: Power BI,Exploratory Data Analysis: Jupyter Notebook + SQL Server + pyspark,,,,"['Sqoop', 'Pysftp']","[{'Sqoop': 1}, {'Pysftp': 1}]",[],[],['Pyspark'],[{'Pyspark': 1}],['Bi bi'],[{'Bi bi': 1}],"['Sql server', 'Pyspark']","[{'Sql server': 1}, {'Pyspark': 1}]"
1659362329.0,electric_creamsicle,1,Airflow deployed on GKE mostly running k8s pod operators or BigQuery jobs. Starting to shift a good portion of the extract and load layer to streaming and follow a ELT pattern.,BigQuery. Larger datasets are stored in Parquet on Cloud Storage.,SQL usually ran from Airflow,"A mix of folks doing their own BI with Jupyter Notebooks or whatever tooling they're comfortable with, some Tableau, a little bit of Google Data Studio",I think this is mostly just SQL for warehoused data. We also have a separate tracking events SaaS that is probably the first entrypoint into exploratory stuff.,~2000 total but probably only 500 or so working with data in some capacity on a regular basis,Travel,"Montreal, Canada but like 80% of the company is fully remote","['Follow elt pattern', 'Airflow deployed gke mostly running k8s pod operators', 'Bigquery jobs starting shift portion extract', 'Load layer streaming']","[{'Follow elt pattern': 1}, {'Airflow deployed gke mostly running k8s pod operators': 1}, {'Bigquery jobs starting shift portion extract': 1}, {'Load layer streaming': 1}]",['Bigquery larger datasets stored parquet storage'],[{'Bigquery larger datasets stored parquet storage': 1}],['Sql usually airflow'],[{'Sql usually airflow': 1}],['Tableau'],[{'Tableau': 1}],['I mostly sql warehoused data tracking events saas probably entrypoint into exploratory stuff'],[{'I mostly sql warehoused data tracking events saas probably entrypoint into exploratory stuff': 1}]
1659365541.0,alpinewerks,1,Talend,MS SQL on-prem,Talend,Tableau,Tableau / R,300,Financial Services,USA,['Talend'],[{'Talend': 1}],['Ms sql onprem'],[{'Ms sql onprem': 1}],['Talend'],[{'Talend': 1}],['Tableau'],[{'Tableau': 1}],"['Tableau', 'R']","[{'Tableau': 1}, {'R': 1}]"
1659371800.0,majc2,1,SSIS / Airflow,MSSQL,SSIS / Stored Procedures,PBI,R,400k+,Automotive,Germany,"['Airflow', 'Ssis']","[{'Airflow': 1}, {'Ssis': 1}]",['Mssql'],[{'Mssql': 1}],['Ssis'],[{'Ssis': 1}],[],[],['R'],[{'R': 1}]
1659386547.0,sergiojulio,1,0000,,,,,,,,['0000'],[{'0000': 1}],[''],[{'': 1}],[''],[{'': 1}],[''],[{'': 1}],[''],[{'': 1}]
1659457194.0,Strange_Temporary_41,1,"Etl: airflow for orchestrate, airbyte for ingest",Dwh: bigquery,"Transform: airflow, dataflow","Bi: superset, google studio","Eda: colab , jupyter notebook",Size:200,Ecommerce,Vietnam,[],[],[],[],['Dataflow'],[{'Dataflow': 1}],"['Google studio', 'Bi superset']","[{'Google studio': 1}, {'Bi superset': 1}]",[],[]
1659532554.0,edthix,2,"Airflow (mostly from GCP CloudSQL Postgresql), Fivetran (social media connectors)",": we're entirely on gcp, so instead of s3 it's gcs when it comes to ephemeral storage needs for ETL etc.",Mixture of Airflow and BigQuery scheduler,"DataStudio (now) looking to move to Tableu/Looker, depends on $$","Jupyter notebooks via GCP Workbench or BigQuery sql console, depends on team",300,Education,,[],[],['Instead s3 its gcs comes ephemeral storage needs etl etc'],[{'Instead s3 its gcs comes ephemeral storage needs etl etc': 2}],['Bigquery scheduler'],[{'Bigquery scheduler': 2}],['Looker'],[{'Looker': 2}],"['Depends team', 'Jupyter notebooks via gcp workbench', 'Bigquery sql console']","[{'Depends team': 2}, {'Jupyter notebooks via gcp workbench': 2}, {'Bigquery sql console': 2}]"
1659722549.0,maximize_futility,1,from MySQL via Python scripts in AWS Lambda,BigQuery,dbt,Metabase (formerly - DataStudio + Mode),equals.app,\~15,Foodtech,"NYC, USA",['From mysql via python scripts aws lambda'],[{'From mysql via python scripts aws lambda': 1}],[],[],['Dbt'],[{'Dbt': 1}],[],[],['Equalsapp'],[{'Equalsapp': 1}]
